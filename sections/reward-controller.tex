The problem with history-based rewards is that we have to remember all the previous observations and only then calculate the associated reward, instead of simply calculating the reward per transition. 

In this chapter we are going to take the history-based reward function and transform it into something more tangible. We are going to transform it into an abstract machine that keeps track of its history and rewards associated. 

First we'll give a formal definition of the machine we are using to represent the reward function. In \secref{sec:rc-sequences} we will describe how to obtain such a machine given a list of observation sequences together with their rewards and in \secref{sec:rc-regex} we do the same but for a series of regular expressions. 

\input{sections/reward-controller/definition.tex}

\input{sections/reward-controller/sequences.tex}

\input{sections/reward-controller/regular-expressions.tex}

