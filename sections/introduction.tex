\par
\section*{Motivating Example}

\section*{Problem Formulation}
Given a POMDP with a history-based reward function, obtain a policy that maximizes the expected reward.

\section*{Contribution}

\section*{Structure}
first preliminaries, then definitions 
chapter 4 we present reward controllers, i.e. give a structure on how to model the reward function. in chapter 5 we combine the original pomdp with the created reward controller to obtain an markov model again. 